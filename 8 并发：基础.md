1. [#55: 混淆并发和并行](#55-混淆并发和并行)
2. [#56: 认为并发总是更快](#56-认为并发总是更快)
3. [#57: 对何时使用 channel 或互斥锁感到困惑](#57-对何时使用-channel-或互斥锁感到困惑)
4. [#58：不理解竞争问题](#58不理解竞争问题)
5. [#59：不了解工作负载类型对并发的影响](#59不了解工作负载类型对并发的影响)
6. [#60：误解 Go 上下文](#60误解-go-上下文)


总结：
- 并发是指 goroutine 运行的时候是相互独立的。
- 使用关键字 go 创建 goroutine 来运行函数。
- goroutine 在逻辑处理器上执行，而逻辑处理器具有独立的系统线程和运行队列。
- 竞争状态是指两个或者多个 goroutine 试图访问同一个资源。
- 原子函数和互斥锁提供了一种防止出现竞争状态的办法。
- 通道提供了一种在两个 goroutine 之间共享数据的简单方法。
- 无缓冲的通道保证同时交换数据，而有缓冲的通道不做这种保证。

# #55: 混淆并发和并行



并行是让不同的代码片段同时在不同的物理处理器上执行。并行的关键是同时做很多事情，而并发是指同时管理很多事情，这些事情可能只做
了一半就被暂停去做别的事情了。在很多情况下，并发的效果比并行好，因为操作系统和硬件的
总资源一般很少，但能支持系统同时做很多事情。

如果希望让 goroutine 并行，必须使用多于一个逻辑处理器。当有多个逻辑处理器时，调度器会将 goroutine 平等分配到每个逻辑处理器上。这会让 goroutine 在不同的线程上运行。

>进程看作一个包含了应用程序在运行中需要用到和维护的各种资源的容器。
>一个线程是一个执行空间，这个空间会被操作系统调度来运行函数中所写的代码。每个进程至少包含一个线程，每个进程的初始线程被称作主线程。因为执行这个线程的空间是应用程序的本身的空间，所以当主线程终止时，应用程序也会终止。

操作系统会在物理处理器上调度线程来运行，而 Go 语言的运行时会在逻辑处理器上调度
goroutine来运行。每个逻辑处理器都分别绑定到单个操作系统线程。


只有在有多个逻辑处理器且可以同时让每个goroutine 运行在一个可用的物理处理器上的时候，goroutine 才会并行运行。



# #56: 认为并发总是更快

基于协作的抢占式调度 
我们可以在 pkg/runtime/proc.go 文件中找到引入基于协作的抢占式调度后的调度器。Go 语言会在分段栈的机制上实现抢占调度，利用编译器在分段栈上插入的函数，所有 Goroutine 在函数调用时都有机会进入运行时检查是否需要执行抢占。Go 团队通过以下的多个提交实现该特性：


```go
// Goroutine scheduler
// The scheduler's job is to distribute ready-to-run goroutines over worker threads.
//
// The main concepts are:
// G - goroutine.
// M - worker thread, or machine.
// P - processor, a resource that is required to execute Go code.
//     M must have an associated P to execute Go code, however it can be
//     blocked or in a syscall w/o an associated P.
```

**GO 调度**

线程是操作系统可以执行的最小单元。如果一个进程想要同时执行多个动作，它可以启动多个线程。这些线程可以是：

- 并发——两个或者更多线程可以在同一时间段内启动、运行和完成。
- 并行——同一个任务可以同时执行多次

操作系统负责优化调度线程的那些进程：

- 所有的线程都可以消费 CPU 周期，不会饥饿太久。
- 工作负载尽可能地被均匀分布在不同的 CPU 核上。


- G——Goroutine
- M——操作系统线程（代表 machine）
- P——CPU 核（代表 processor）

每个操作系统线程（M）由操作系统调度器指派给 CPU 核（P），每个 goroutine(G)都会在 M 上运行。
GOMAXPROCS 变量定义了负责同时执行用户级代码的 M 的最大数量。但是如果一个线程在系统调用中被阻塞，调度器可以启动更多的 M。

goroutine 的生命周期比操作系统线性的生命周期更简单。它可以处于下面的状态之一。
- executing——goroutine 被调度在 M 上，并正在执行它的指令。
- running——goroutine 正等待进入 executing 状态。
- waiting——goroutine 暂停并等待某事完成。



**Go 运行时如何实现调度？**

每执行 61 次，Go 调度器会检查全局队列中是否有可用的 Goroutine，如果不可用，它检查它的本地队列。同时，如果全局队列和本地队列都为空，Go 调度器从其他本地对了中挑选一个 goroutine，调度中的这个原则被称为工作窃取(work stealing),它允许未充分利用的 P 主动去寻找另一些 P 的 goroutine，窃取一些 goroutine。


伪代码
```go
runtime.schedule(){
	// 只有 1/61 的次数，来检查全局可运行的队列，去选择一个 G。
	// 如没找到，就检查本地队列。
	// 如果没找到，
	//    尝试从其他 P 的本地队列里窃取一个。
	//    如果还没找到，再检查全局可运行的队列。
	//    如果还没找到，检查处理网络的 goroutine。
}
```

从 Go 1.14 开始，Go 调度器变成了抢占式地：当一个 goroutine 连续运行超过特定的时间(10毫秒)时，它会被标记成科抢占的，并且可以通过上下文切换被另一个 goroutine 替换。这样就强制长时间运行的任务分享一部分 CPU 时间。

**归并排序**

```go
/*
 * @lc app=leetcode.cn id=912 lang=golang
 *
 * [912] 排序数组
 */

// @lc code=start
func sortArray(nums []int) []int {
	mergeSort(nums, 0, len(nums)-1)
	return nums
}

func merge(nums []int, start, mid, end int) {
	tmp := make([]int, end-start+1)
	i, j, k := start, mid+1, 0
	for p := start; p <= end; p++ {
		if i > mid {
			tmp[k] = nums[j]
			j++
		} else if j > end {
			tmp[k] = nums[i]
			i++
		} else if nums[i] <= nums[j] {
			tmp[k] = nums[i]
			i++
		} else {
			tmp[k] = nums[j]
			j++
		}
		k++
	}
	copy(nums[start:end+1], tmp)
}

func mergeSort(nums []int, start, end int) {
	if start >= end {
		return
	}
	mid := start + (end-start)>>1
	mergeSort(nums, start, mid)
	mergeSort(nums, mid+1, end)
	merge(nums, start, mid, end)
}
```

**并行归并排序**


```go
import (
	"sync"
)

func sortArray(nums []int) []int {
	sequentialMergesort(nums)    // 串行      (41 ms) 21/21 cases passed 
	// parallelMergesortV1(nums) // 并行      (699 ms)
	// parallelMergesortV2(nums) // 并行优化   (35 ms)
	return nums
}

func sequentialMergesort(s []int) {
	if len(s) <= 1 {
		return
	}

	middle := len(s) / 2
	sequentialMergesort(s[:middle])
	sequentialMergesort(s[middle:])
	merge(s, middle)
}

func parallelMergesortV1(s []int) {
	if len(s) <= 1 {
		return
	}

	middle := len(s) / 2

	var wg sync.WaitGroup
	wg.Add(2)

	go func() {
		defer wg.Done()
		parallelMergesortV1(s[:middle])
	}()

	go func() {
		defer wg.Done()
		parallelMergesortV1(s[middle:])
	}()

	wg.Wait()
	merge(s, middle)
}

const max = 2048

func parallelMergesortV2(s []int) {
	if len(s) <= 1 {
		return
	}

	if len(s) <= max {
		sequentialMergesort(s)
	} else {
		middle := len(s) / 2

		var wg sync.WaitGroup
		wg.Add(2)

		go func() {
			defer wg.Done()
			parallelMergesortV2(s[:middle])
		}()

		go func() {
			defer wg.Done()
			parallelMergesortV2(s[middle:])
		}()

		wg.Wait()
		merge(s, middle)
	}
}

func merge(s []int, middle int) {
	helper := make([]int, len(s))
	copy(helper, s)

	helperLeft := 0
	helperRight := middle
	current := 0
	high := len(s) - 1

	for helperLeft <= middle-1 && helperRight <= high {
		if helper[helperLeft] <= helper[helperRight] {
			s[current] = helper[helperLeft]
			helperLeft++
		} else {
			s[current] = helper[helperRight]
			helperRight++
		}
		current++
	}

	for helperLeft <= middle-1 {
		s[current] = helper[helperLeft]
		current++
		helperLeft++
	}
}
```

如果想要并行化的工作负载很小，也就意味着计算工作的负载的速度太快，那么跨 CPU 核分配工作的好处也就不存在了：与直接合并当前 goroutine 中的少量元素所花费的时间相比，创建一个 goroutine 并让调度器执行它所花费的时间来说太多了。尽管 goroutine 比线程更轻量，启动更快，但我们仍然会遇到工作负载太小的情况。

并发并不总是较快，不应该将其视为解决所有问题的默认方法。首先它使问题变得更加复杂，此外，现代 CPU 在执行串行代码和可预测代码方面变得异常高效。启动 goroutine 来处理最小的工作负载（只合并一小部分元素）破坏了从并发中获得的好处。

如果不确定并行版本会更快，正确的做法可能是从简单的串行版本开始，然后可使用分析（#98）和基础测试（#89）进行分析测试，这可能是确保并发是否有价值的唯一方法。


# #57: 对何时使用 channel 或互斥锁感到困惑

**并行 goroutine 需要互斥锁，并发 goroutine 需要 channel**

- 并行 goroutine 之间的同步应该通过互斥锁来实现

>并行 goroutine 必须同步，当它们需要访问或者改变共享资源时，使用互斥锁可以强制同步，不使用任何 channel 类型（包括不使用 buffered channel）。

- 并发 goroutine 通常协作和编排。

>当我们想要共享状态或者访问共享资源的时候，互斥锁能确保对该资源的独占访问。
>channel 是一种通信机制，在有或者没有数据的情况下发出信号。协作或者所有权转移应该使用 channel 实现。

# #58：不理解竞争问题

**数据竞争与竞争条件**

- 竞争条件检测
>只要在go build，go run或者go test命令后面加上-race的flag，就会使编译器创建一个你的应用的“修改”版或者一个附带了能够记录所有运行期对共享变量访问工具的test，并且会记录下每一个读或者写共享变量的goroutine的身份信息。

```bash
go test -race -v .

go run -race -v .

go build -race -v .
```

同步 goroutine 的三种技术：原子操作、互斥锁、channel

当多个 goroutine 同时访问一个内存位置时，并且至少其中一个正在写入时，就会发生数据竞争。3种同步方法阻止数据竞争：
- 使用原子操作 
- 使用互斥锁保护临界区 
- 使用通信和 channel 确保变量仅由一个 goroutine 更新



```go
package main

import (
	"fmt"
	"sync"
	"sync/atomic"
)

func listing1() {
	i := 0

	go func() {
		i++
	}()

	go func() {
		i++
	}()
	fmt.Println(i) // 0
}

/*
➜ go run -race main.go

Found 1 data race(s)
*/

func listing2() {
	var i int64

	go func() {
		atomic.AddInt64(&i, 1) // 原子操作加 1
	}()

	go func() {
		atomic.AddInt64(&i, 1)
	}()
}

// 原子操作不能被中断，避免同时进行两次访问

// 互斥锁确保最多只有一个 goroutine 访问临界区
func listing3() {
	i := 0
	mutex := sync.Mutex{}

	go func() {
		mutex.Lock()
		i++
		mutex.Unlock()
	}()

	go func() {
		mutex.Lock()
		i++
		mutex.Unlock()
	}()
}

// 跨 goroutine 通信
func listing4() {
	i := 0
	ch := make(chan int)

	go func() {
		ch <- 1 // 通知 goroutine 进行加 1 操作
	}()

	go func() {
		ch <- 1
	}()

	i += <-ch // 加上从 channel 中读取的值
	i += <-ch
}

// 无数据竞争，但有竞争条件。当行为取决于无法控制的事件顺序或时间时，就会出现竞争条件。
// 互斥锁保证无数据竞争，但无确定结果
func listing5() {
	i := 0
	mutex := sync.Mutex{}

	go func() {
		mutex.Lock()
		defer mutex.Unlock()
		i = 1
	}()

	go func() {
		mutex.Lock()
		defer mutex.Unlock()
		i = 2
	}()

	_ = i
}

func main() {
	listing1()
	listing2()
	listing3()
	listing4()
	listing5()
}
```



**Go 内存模型**

>我们使用符号 A<B 来表示 A 发生在事件 B 之前 （后面我们将 happens before 统一表述成 A happens before B)

```go
package main

import "fmt"

// 创建一个 goroutine 一定 happens before 执行这个 goroutine
func listing1() {
	i := 0
	go func() {
		i++
	}()
}

// goroutine 的退出不能保证 happens before 其他事件，所以下面的代码有数据竞争
func listing2() {
	i := 0
	go func() {
		i++
	}()
	fmt.Println(i)
}

// 执行顺序：变量加1<从channel发送<从channel读取<变量读取
func listing3() {
	i := 0
	ch := make(chan struct{})
	go func() {
		<-ch           // 3
		fmt.Println(i) // 4
	}()
	i++              // 1
	ch <- struct{}{} // 2
}

func listing4() {
	i := 0
	ch := make(chan struct{})
	go func() {
		<-ch
		fmt.Println(i)
	}()
	i++
	close(ch)
}

func listing5() {
	i := 0
	ch := make(chan struct{}, 1)//channel是缓冲的，会导致数据竞争
	go func() {
		i = 1
		<-ch
	}()
	ch <- struct{}{}
	fmt.Println(i)//对变量i的读和写可能同时发生
}

func listing6() {
	i := 0
	ch := make(chan struct{})//非缓冲channel，无数据竞争
	go func() {
		i = 1
		<-ch
	}()
	ch <- struct{}{}
	fmt.Println(i)
}
```


# #59：不了解工作负载类型对并发的影响

在程序执行时，工作负载的执行时间会受以下因素限制：
- CPU 的速度——CPU 密集型
- I/O 速度——I/O 密集型
- 可用内存量——内存密集型



# #60：误解 Go 上下文





