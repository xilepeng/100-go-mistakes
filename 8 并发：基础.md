1. [#55: 混淆并发和并行](#55-混淆并发和并行)
2. [#56: 认为并发总是更快](#56-认为并发总是更快)


总结：
- 并发是指 goroutine 运行的时候是相互独立的。
- 使用关键字 go 创建 goroutine 来运行函数。
- goroutine 在逻辑处理器上执行，而逻辑处理器具有独立的系统线程和运行队列。
- 竞争状态是指两个或者多个 goroutine 试图访问同一个资源。
- 原子函数和互斥锁提供了一种防止出现竞争状态的办法。
- 通道提供了一种在两个 goroutine 之间共享数据的简单方法。
- 无缓冲的通道保证同时交换数据，而有缓冲的通道不做这种保证。

# #55: 混淆并发和并行



并行是让不同的代码片段同时在不同的物理处理器上执行。并行的关键是同时做很多事情，而并发是指同时管理很多事情，这些事情可能只做
了一半就被暂停去做别的事情了。在很多情况下，并发的效果比并行好，因为操作系统和硬件的
总资源一般很少，但能支持系统同时做很多事情。

如果希望让 goroutine 并行，必须使用多于一个逻辑处理器。当有多个逻辑处理器时，调度器会将 goroutine 平等分配到每个逻辑处理器上。这会让 goroutine 在不同的线程上运行。

>进程看作一个包含了应用程序在运行中需要用到和维护的各种资源的容器。
>一个线程是一个执行空间，这个空间会被操作系统调度来运行函数中所写的代码。每个进程至少包含一个线程，每个进程的初始线程被称作主线程。因为执行这个线程的空间是应用程序的本身的空间，所以当主线程终止时，应用程序也会终止。

操作系统会在物理处理器上调度线程来运行，而 Go 语言的运行时会在逻辑处理器上调度
goroutine来运行。每个逻辑处理器都分别绑定到单个操作系统线程。


只有在有多个逻辑处理器且可以同时让每个goroutine 运行在一个可用的物理处理器上的时候，goroutine 才会并行运行。



# #56: 认为并发总是更快

基于协作的抢占式调度 
我们可以在 pkg/runtime/proc.go 文件中找到引入基于协作的抢占式调度后的调度器。Go 语言会在分段栈的机制上实现抢占调度，利用编译器在分段栈上插入的函数，所有 Goroutine 在函数调用时都有机会进入运行时检查是否需要执行抢占。Go 团队通过以下的多个提交实现该特性：


```go
// Goroutine scheduler
// The scheduler's job is to distribute ready-to-run goroutines over worker threads.
//
// The main concepts are:
// G - goroutine.
// M - worker thread, or machine.
// P - processor, a resource that is required to execute Go code.
//     M must have an associated P to execute Go code, however it can be
//     blocked or in a syscall w/o an associated P.
```

**GO 调度**

线程是操作系统可以执行的最小单元。如果一个进程想要同时执行多个动作，它可以启动多个线程。这些线程可以是：

- 并发——两个或者更多线程可以在同一时间段内启动、运行和完成。
- 并行——同一个任务可以同时执行多次

操作系统负责优化调度线程的那些进程：

- 所有的线程都可以消费 CPU 周期，不会饥饿太久。
- 工作负载尽可能地被均匀分布在不同的 CPU 核上。


- G——Goroutine
- M——操作系统线程（代表 machine）
- P——CPU 核（代表 processor）

每个操作系统线程（M）由操作系统调度器指派给 CPU 核（P），每个 goroutine(G)都会在 M 上运行。
GOMAXPROCS 变量定义了负责同时执行用户级代码的 M 的最大数量。但是如果一个线程在系统调用中被阻塞，调度器可以启动更多的 M。

goroutine 的生命周期比操作系统线性的生命周期更简单。它可以处于下面的状态之一。
- executing——goroutine 被调度在 M 上，并正在执行它的指令。
- running——goroutine 正等待进入 executing 状态。
- waiting——goroutine 暂停并等待某事完成。



**Go 运行时如何实现调度？**

每执行 61 次，Go 调度器会检查全局队列中是否有可用的 Goroutine，如果不可用，它检查它的本地队列。同时，如果全局队列和本地队列都为空，Go 调度器从其他本地对了中挑选一个 goroutine，调度中的这个原则被称为工作窃取(work stealing),它允许未充分利用的 P 主动去寻找另一些 P 的 goroutine，窃取一些 goroutine。


伪代码
```go
runtime.schedule(){
	// 只有 1/61 的次数，来检查全局可运行的队列，去选择一个 G。
	// 如没找到，就检查本地队列。
	// 如果没找到，
	//    尝试从其他 P 的本地队列里窃取一个。
	//    如果还没找到，再检查全局可运行的队列。
	//    如果还没找到，检查处理网络的 goroutine。
}
```

从 Go 1.14 开始，Go 调度器变成了抢占式地：当一个 goroutine 连续运行超过特定的时间(10毫秒)时，它会被标记成科抢占的，并且可以通过上下文切换被另一个 goroutine 替换。这样就强制长时间运行的任务分享一部分 CPU 时间。

**归并排序**

```go
/*
 * @lc app=leetcode.cn id=912 lang=golang
 *
 * [912] 排序数组
 */

// @lc code=start
func sortArray(nums []int) []int {
	mergeSort(nums, 0, len(nums)-1)
	return nums
}

func merge(nums []int, start, mid, end int) {
	tmp := make([]int, end-start+1)
	i, j, k := start, mid+1, 0
	for p := start; p <= end; p++ {
		if i > mid {
			tmp[k] = nums[j]
			j++
		} else if j > end {
			tmp[k] = nums[i]
			i++
		} else if nums[i] <= nums[j] {
			tmp[k] = nums[i]
			i++
		} else {
			tmp[k] = nums[j]
			j++
		}
		k++
	}
	copy(nums[start:end+1], tmp)
}

func mergeSort(nums []int, start, end int) {
	if start >= end {
		return
	}
	mid := start + (end-start)>>1
	mergeSort(nums, start, mid)
	mergeSort(nums, mid+1, end)
	merge(nums, start, mid, end)
}
```

**并行归并排序**


```go
import (
	"sync"
)

func sortArray(nums []int) []int {
	sequentialMergesort(nums)    // 串行      (41 ms) 21/21 cases passed 
	// parallelMergesortV1(nums) // 并行      (699 ms)
	// parallelMergesortV2(nums) // 并行优化   (35 ms)
	return nums
}

func sequentialMergesort(s []int) {
	if len(s) <= 1 {
		return
	}

	middle := len(s) / 2
	sequentialMergesort(s[:middle])
	sequentialMergesort(s[middle:])
	merge(s, middle)
}

func parallelMergesortV1(s []int) {
	if len(s) <= 1 {
		return
	}

	middle := len(s) / 2

	var wg sync.WaitGroup
	wg.Add(2)

	go func() {
		defer wg.Done()
		parallelMergesortV1(s[:middle])
	}()

	go func() {
		defer wg.Done()
		parallelMergesortV1(s[middle:])
	}()

	wg.Wait()
	merge(s, middle)
}

const max = 2048

func parallelMergesortV2(s []int) {
	if len(s) <= 1 {
		return
	}

	if len(s) <= max {
		sequentialMergesort(s)
	} else {
		middle := len(s) / 2

		var wg sync.WaitGroup
		wg.Add(2)

		go func() {
			defer wg.Done()
			parallelMergesortV2(s[:middle])
		}()

		go func() {
			defer wg.Done()
			parallelMergesortV2(s[middle:])
		}()

		wg.Wait()
		merge(s, middle)
	}
}

func merge(s []int, middle int) {
	helper := make([]int, len(s))
	copy(helper, s)

	helperLeft := 0
	helperRight := middle
	current := 0
	high := len(s) - 1

	for helperLeft <= middle-1 && helperRight <= high {
		if helper[helperLeft] <= helper[helperRight] {
			s[current] = helper[helperLeft]
			helperLeft++
		} else {
			s[current] = helper[helperRight]
			helperRight++
		}
		current++
	}

	for helperLeft <= middle-1 {
		s[current] = helper[helperLeft]
		current++
		helperLeft++
	}
}
```

如果想要并行化的工作负载很小，也就意味着计算工作的负载的速度太快，那么跨 CPU 核分配工作的好处也就不存在了：与直接合并当前 goroutine 中的少量元素所花费的时间相比，创建一个 goroutine 并让调度器执行它所花费的时间来说太多了。尽管 goroutine 比线程更轻量，启动更快，但我们仍然会遇到工作负载太小的情况。

并发并不总是较快，不应该将其视为解决所有问题的默认方法。首先它使问题变得更加复杂，此外，现代 CPU 在执行串行代码和可预测代码方面变得异常高效。启动 goroutine 来处理最小的工作负载（只合并一小部分元素）破坏了从并发中获得的好处。

如果不确定并行版本会更快，正确的做法可能是从简单的串行版本开始，然后可使用分析（#98）和基础测试（#89）进行分析测试，这可能是确保并发是否有价值的唯一方法。
